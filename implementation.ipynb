{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Implementation of Easy Ensemble\n",
    "```\n",
    "Tatsuhito Hasegawa, Kazuma Kondo,\n",
    "\"Easy Ensemble: Simple Deep Ensemble Learning for Sensor-Based Human Activity Recognition\",\n",
    "arXiv:2203.04153,\n",
    "https://arxiv.org/abs/2203.04153\n",
    "```\n",
    "\n",
    "## Rule\n",
    "Most CNN modules can be EE style by modifying each of layer as follows:\n",
    "\n",
    "1. Set the hyperparameter of groups as $N$ of the convolution layer to change to group convolution (same for the point-wise convolution layer).\n",
    "2. Change normalization layer to group normalization  by setting the group parameter to $N$.\n",
    "3. Because the fully-connected layer is equivalent to a one-dimensional convolution layer with a kernel size of 1, change the fully-connected layer to reshape and the group convolution layer.\n",
    "4. Multiply output $\\boldsymbol{z}$ of E by $\\frac{1}{N}$.\n",
    "\n",
    "Notably, the activation function, pooling layer, depth-wise convolution layer, and shortcut connection are processed independently in the channel direction; therefore, they do not need to be changed. Using these simple procedures, most CNN architectures can be in the EE style.\n",
    "\n",
    "## Pytorch example\n",
    "1. Set the hyperparameter of groups as $N$ of the convolution layer to change to group convolution (same for the point-wise convolution layer).\n",
    "\n",
    "```python\n",
    "    from torch import nn\n",
    "    N = 4  # the number of ensembles\n",
    "    general_conv = nn.Conv1d(3, 64, kernel_size=3, padding=1, bias=False, groups=1)  # old style\n",
    "    ee_conv = nn.Conv1d(3 * N, 64 * N, kernel_size=3, padding=1, bias=False, groups=N)  # EE style\n",
    "```\n",
    "\n",
    "2. Change normalization layer to group normalization  by setting the group parameter to $N$.\n",
    "\n",
    "```python\n",
    "    general_norm = nn.GroupNorm(1, 64, affine=False)  # old style (Layer normalization)\n",
    "    ee_norm = nn.GroupNorm(N, 64 * N, affine=False)  # EE style (Group normalization)\n",
    "```\n",
    "\n",
    "3. Because the fully-connected layer is equivalent to a one-dimensional convolution layer with a kernel size of 1, change the fully-connected layer to reshape and the group convolution layer.\n",
    "```python\n",
    "    general_linear = nn.Linear(64, 128, bias=False)  # old style (Linear: 64 to 128)\n",
    "    ee_norm = nn.Sequential(  # EE style (Linear: (64 to 128) * N)\n",
    "                View(-1, 64 * N, 1),   # the original reshape module (see. https://discuss.pytorch.org/t/how-to-build-a-view-layer-in-pytorch-for-sequential-models/53958)\n",
    "                nn.Conv1d(64 * N, 128 * N, kernel_size=1, bias=False, groups=N),\n",
    "                View(-1, 128 * N)      # this layer can also be substituted with Flatten.\n",
    "              )\n",
    "```\n",
    "\n",
    "## Example implementation of VGG in Pytorch\n",
    "VGG is a CNN model composed of only simple convolution modules.\n",
    "We describe the example implementation through translation of common VGG to EE-style VGG.\n",
    "VGG is suitable to describe how to implementate the EE because VGG does not include complex techniques.\n",
    "\n",
    "```\n",
    "K. Simonyan and A. Zisserman,\n",
    "“Very deep convolutional networks for large-scale image recognition,”\n",
    "in Proc. of the International Conferenceon Learning Representations, May 2015, pp. 1–14.\n",
    "https://arxiv.org/abs/1409.1556\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=6, nb_fils=64, reps=[1,1,2,2,2], groups=1):\n",
    "        super(VGG, self).__init__()\n",
    "        self.groups = groups\n",
    "        self.encoder = nn.Sequential(\n",
    "            cbrp1d(in_channels, nb_fils, reps[0], groups=groups),\n",
    "            cbrp1d(nb_fils, nb_fils * 2, reps[1], groups=groups),\n",
    "            cbrp1d(nb_fils * 2, nb_fils * 4, reps[2], groups=groups),\n",
    "            cbrp1d(nb_fils * 4, nb_fils * 8, reps[3], groups=groups),\n",
    "            cbrp1d(nb_fils * 8, nb_fils * 8, reps[4], groups=groups)\n",
    "            )\n",
    "        self.output_channels = nb_fils * 8\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.output_channels, num_classes, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.avg_pool1d(x, kernel_size=x.size()[2:])  # GAP\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# n-times (convolution, layernorm, relu) and maxpooling\n",
    "def cbrp1d(in_fils, out_fils, rep, groups=1):\n",
    "    layers = []\n",
    "    i_f, o_f = in_fils, out_fils\n",
    "    for _ in range(rep):\n",
    "        layers.append(nn.Conv1d(i_f, o_f, kernel_size=3, padding=1, bias=False, groups=groups))\n",
    "        layers.append(nn.GroupNorm(groups, o_f, affine=False))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        i_f = o_f\n",
    "    layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Original VGG is created (groups=1)\n",
    "vgg = VGG(3, 6, 64, [1,1,2,2,2], groups=1)\n",
    "\n",
    "# EE VGG is created (groups=N)\n",
    "N = 4\n",
    "EE_vgg = VGG(3 * N, 6, 64 * N, [1,1,2,2,2], groups=N)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above implementation of VGG is based on the original VGG architecture.\n",
    "From original modle, we modified following two points:\n",
    "\n",
    "1. insert layer-normalizaiton after each convolution.\n",
    "2. replace the flatten layer to global average pooling and flatten layers.\n",
    "\n",
    "these two points are not related to EE.\n",
    "\n",
    "To translate original VGG to EE style, we only modified the cbrp1d module by adding the groups hyperparameter in Conv1d and GroupNorm.\n",
    "If these two groups parameters are set to 1, this module works as original VGG.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}